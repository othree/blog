<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/main.xsl"?>
<b:blog xmlns="http://www.w3.org/1999/xhtml" xmlns:b="http://blog.othree.net"  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://blog.othree.net http://blog.othree.net/blooog.xsd">
	<b:blogTitle>O3noBLOG</b:blogTitle>
	<b:blogDescription></b:blogDescription>
	<b:entries>
		<b:entriesMeta>
			<b:listType>s</b:listType>
			<b:listData listID="000579" baseName="opera-face-gesture-and-more">Opera Face Gesture 與其它</b:listData>

			<b:previous>
				<b:mTitle>The Web of Linked Open Data</b:mTitle>
				<b:mDate>2009-04-21</b:mDate>
				<b:mBase>linked-open-data</b:mBase>
			</b:previous>


			<b:next>
				<b:mTitle>Handle IE</b:mTitle>
				<b:mDate>2009-04-27</b:mDate>
				<b:mBase>handle-ie</b:mBase>
			</b:next>

		</b:entriesMeta>
		<b:entry entryID="000579" baseName="opera-face-gesture-and-more">
			<b:author>
				<b:authorName>othree</b:authorName>
				<b:authorEmail>othree@gmail.com</b:authorEmail>
				<b:authorUrl></b:authorUrl>
			</b:author>
			<b:datetime>
				<b:date>2009-04-25</b:date>
				<b:time>10:11:29</b:time>
			</b:datetime>
			<b:category>web</b:category>

			<b:CommentsAccepted>0</b:CommentsAccepted>


			<b:PingsAccepted>0</b:PingsAccepted>

			<b:title>Opera Face Gesture 與其它</b:title>
			<b:content>
				<b:summary>首先來看一下 Opera 在今年愚人節推出的臉部表情控制吧。...</b:summary>
				<b:mainContent><p>首先來看一下 Opera 在今年愚人節推出的<a href="http://labs.opera.com/news/2009/04/01/">臉部表情控制</a>吧。</p>

<p><iframe width="640" height="360" src="//www.youtube.com/embed/kkNxbyp6thM" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p></b:mainContent>
				<b:extendContent><p>應該很多人看過了，我想大部分人應該都會笑一笑看過去（聽說有人當真了@@），不過我確實覺得這東西有機會做出來，這想法是來自另外兩段影片，首先第一段是 <a href="http://johnnylee.net/projects/wii/">Jonny Lee</a> 的 <a href="http://www.ted.com/index.php/talks/johnny_lee_demos_wii_remote_hacks.html">TED Talk</a>，Jonny Lee 在 Wii 上市後，用它的控制器作為互動介面弄了不少有趣的玩意，他在 TED Talk 介紹了其中兩個，第二個是很有趣的 3D 應用，利用 Wii Remote 和 Sensor Bar 來判斷視點相對於螢幕的位置和角度，依據這些資訊來改變畫面，用單純的螢幕做出更接近真實的3D效果，機下來就來看看這段影片吧。</p>

<p><iframe src="https://embed-ssl.ted.com/talks/johnny_lee_demos_wii_remote_hacks.html" width="640" height="360" frameborder="0" scrolling="no" allowfullscreen="allowfullscreen"></iframe></p>

<p>接著第三段影片做的事情和 Johnny Lee 做的事情一樣，不過用的技術和用途也不太一樣，這是日本 H-Game 公司 <a href="http://www.teatime.ne.jp/">TEATIME</a> 推出的 <a href="http://www.teatime.ne.jp/infor/tech48/tech48_index.htm">Face Tracking</a> 技術，不過他的原理是用 Web Cam 來做臉部辨識，然後判斷臉部和螢幕的相對位置，藉以改變視點，如果視點很低的話，遊戲中的女生也會有相對的反應出來，官方網頁上有影片可以下載來看，不過 YouTube 上也有人上傳了（已經被刪除）。</p>

<p>看著第三影片後，就覺得這技術似乎有機會實現臉部表情控制，至於為什麼要實現，我是想過或許可以作為輔助的操控手，或是讓無法用手腳操控的人使用吧，現在相關的輔助控制我比較知道的是用眼球追蹤啦。</p></b:extendContent>
			</b:content>
			<b:comments commentCount="1">

				<b:comment commentID="098589" entryID="000579">
					<b:author>
						<b:authorName>roid</b:authorName>
						<b:authorEmail></b:authorEmail>
						<b:authorUrl></b:authorUrl>
					</b:author>
					<b:datetime>
						<b:date>2009-05-14</b:date>
						<b:time>22:04:23</b:time>
					</b:datetime>
					<b:content>
						<b:mainContent><p>那個&#8230;臉部表情控制幾週前已經有人實做了一個beta出來了
<a href="http://smert.net/2009/04/23/opera-face-gestures-beta/" rel="nofollow">http://smert.net/2009/04/23/opera-face-gestures-beta/</a></p>
</b:mainContent>
					</b:content>
				</b:comment>

			</b:comments>
			<b:trackbacks trackbackCount="0" trackbackURL="https://othree.net/mt/mt-tb.cgi/577">

			</b:trackbacks>
		</b:entry>
	</b:entries>
</b:blog>